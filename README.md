# Evaluaci√≥n de Rendimiento: Multiplicaci√≥n de Matrices

## üìò Descripci√≥n

Este proyecto tiene como objetivo evaluar el rendimiento de diferentes implementaciones paralelas para la multiplicaci√≥n de matrices (Fork, OpenMP y POSIX Threads), utilizando distintos sistemas y configuraciones de hardware.

## üß† Objetivos

- Comparar el rendimiento de distintas estrategias de paralelismo en la multiplicaci√≥n de matrices.
- Analizar el impacto del n√∫mero de hilos y del hardware en el tiempo de ejecuci√≥n.
- Identificar posibles cuellos de botella o anomal√≠as en la ejecuci√≥n paralela.

## üñ•Ô∏è Plataformas de Evaluaci√≥n

Se realizaron experimentos en 5 sistemas distintos con las siguientes caracter√≠sticas:

| Sistema | Procesador                 | N√∫cleos | RAM     | SO                |
|--------|-----------------------------|---------|---------|-------------------|
| 1      | Intel Core i7-7600U         | 2       | 16 GB   | Ubuntu 18.04 LTS  |
| 2      | AMD Ryzen 5 5600H           | 6       | 7.64 GB | Ubuntu 24.04 LTS  |
| 3      | AMD Ryzen 7 7435HS          | 8       | 16 GB   | ArchLinux         |
| 4      | AMD EPYC 7B13               | 4       | 64 GB   | Ubuntu 20.04 LTS  |
| 5      | Intel Xeon Gold 6240R       | 1       | 12 GB   | Ubuntu 22.04 LTS  |

## ‚öôÔ∏è Configuraci√≥n Experimental

- **Tama√±os de matriz**: 500x500, 1000x1000, 2000x2000
- **N√∫mero de hilos**: 1, 2, 4, 8, 16
- **Repeticiones por configuraci√≥n**: 30 veces
- **M√©trica principal**: Tiempo de ejecuci√≥n promedio (ms)

## üìä Principales Resultados

- OpenMP result√≥ ser la implementaci√≥n m√°s r√°pida en la mayor√≠a de las pruebas.
- El Sistema 3 (Ryzen 7, 8 n√∫cleos) fue el m√°s eficiente, especialmente con OpenMP.
- En sistemas con pocos n√∫cleos (e.g., Sistema 1), el rendimiento se estabiliza o incluso empeora al usar m√°s de 4 hilos.
- Se identific√≥ una **anomal√≠a significativa** en el Sistema 2 con OpenMP usando 2 hilos, donde el tiempo fue mayor que con 1 hilo.

## üìå An√°lisis Destacado

- **OpenMP**: Mejor rendimiento general, pero con posibles problemas de planificaci√≥n o sobrecarga en ciertas configuraciones.
- **Fork**: Escala bien, pero es m√°s costoso por la creaci√≥n de procesos.
- **POSIX Threads**: Rendimiento m√°s estable, especialmente con divisi√≥n expl√≠cita del trabajo.

## üìà Conclusiones

- El paralelismo mejora significativamente el rendimiento, especialmente con matrices grandes y m√°s n√∫cleos.
- El n√∫mero de hilos √≥ptimo depende del hardware. M√°s no siempre es mejor.
- La planificaci√≥n de hilos y el manejo eficiente de la memoria son clave para evitar cuellos de botella.

## üõ†Ô∏è Recomendaciones T√©cnicas

- Usar `schedule(dynamic)` en OpenMP para evitar falso uso compartido.
- Usar herramientas como `perf` para perfilar el uso de cach√© y CPU.
- Considerar alineaci√≥n de memoria para optimizar el acceso.

## üìö Repositorios del Proyecto

- [Jeol28/Taller-de-Evaluacion](https://github.com/Jeol28/Taller-de-Evaluacion)
- [Alviz09/SisOpsTallerEvaluacion](https://github.com/Alviz09/SisOpsTallerEvaluacion)
- [CarlitosPinzon/TallerEvaluaci-n](https://github.com/CarlitosPinzon/TallerEvaluaci-n)
- [Danielhoyos06/Tallerevaluacionrend](https://github.com/Danielhoyos06/Tallerevaluacionrend)
- [Gantu78/TallerEvaluaciondeRendimiento](https://github.com/Gantu78/TallerEvaluaciondeRendimiento)

---

**Autores:**  
Juan Sebasti√°n √Ålvarez, Daniel Hoyos, Carlos Santiago Pinz√≥n Caicedo, Samuel Jer√≥nimo Gantiva Garz√≥n, Jorge Enrique Olaya Li√©vano  
**Curso:** Sistemas Operativos ‚Äì Pontificia Universidad Javeriana  
**Profesor:** John Corredor, Ph.D.  
**Fecha:** 1 de mayo de 2025
